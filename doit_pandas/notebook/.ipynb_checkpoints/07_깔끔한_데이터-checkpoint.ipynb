{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 07. 깔끔한 데이터"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 07-1. 열과 피벗"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__넓은 데이터__\n",
    "열 이름이 어떤 값을 의미할 경우 열이 옆으로 길게 늘어선 형태가 된다. 이런 데이터를 '넓은 데이터'라고 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__melt 메서드__ 넓은 데이터에서 지정한 열의 데이터를 모두 행으로 정리해 준다.\n",
    "- __메서드 인자__\n",
    " - id_var : 위치를 유지할 열 지정\n",
    " - value_vars : 행으로 위치를 변경할 열 지정\n",
    " - var_name : 위치를 변경한 열 이름 지정\n",
    " - value_name : 위치를 변경한 열의 데이터를 저장할 열 이름 지정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## melt 메서드 사용하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 1개의 열만 고정하고 나머지 열을 행으로 바꾸기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             religion  <$10k  $10-20k  $20-30k  $30-40k  $40-50k  $50-75k  \\\n",
      "0            Agnostic     27       34       60       81       76      137   \n",
      "1             Atheist     12       27       37       52       35       70   \n",
      "2            Buddhist     27       21       30       34       33       58   \n",
      "3            Catholic    418      617      732      670      638     1116   \n",
      "4  Don’t know/refused     15       14       15       11       10       35   \n",
      "\n",
      "   $75-100k  $100-150k  >150k  Don't know/refused  \n",
      "0       122        109     84                  96  \n",
      "1        73         59     74                  76  \n",
      "2        62         39     53                  54  \n",
      "3       949        792    633                1489  \n",
      "4        21         17     18                 116  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pew = pd.read_csv('../data/pew.csv')\n",
    "print(pew.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   religion  <$10k  $10-20k  $20-30k  $30-40k  $40-50k\n",
      "0                  Agnostic     27       34       60       81       76\n",
      "1                   Atheist     12       27       37       52       35\n",
      "2                  Buddhist     27       21       30       34       33\n",
      "3                  Catholic    418      617      732      670      638\n",
      "4        Don’t know/refused     15       14       15       11       10\n",
      "5          Evangelical Prot    575      869     1064      982      881\n",
      "6                     Hindu      1        9        7        9       11\n",
      "7   Historically Black Prot    228      244      236      238      197\n",
      "8         Jehovah's Witness     20       27       24       24       21\n",
      "9                    Jewish     19       19       25       25       30\n",
      "10            Mainline Prot    289      495      619      655      651\n",
      "11                   Mormon     29       40       48       51       56\n",
      "12                   Muslim      6        7        9       10        9\n",
      "13                 Orthodox     13       17       23       32       32\n",
      "14          Other Christian      9        7       11       13       13\n",
      "15             Other Faiths     20       33       40       46       49\n",
      "16    Other World Religions      5        2        3        4        2\n",
      "17             Unaffiliated    217      299      374      365      341\n"
     ]
    }
   ],
   "source": [
    "print(pew.iloc[:,0:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    religion            variable  value\n",
      "0                   Agnostic               <$10k     27\n",
      "1                    Atheist               <$10k     12\n",
      "2                   Buddhist               <$10k     27\n",
      "3                   Catholic               <$10k    418\n",
      "4         Don’t know/refused               <$10k     15\n",
      "5           Evangelical Prot               <$10k    575\n",
      "6                      Hindu               <$10k      1\n",
      "7    Historically Black Prot               <$10k    228\n",
      "8          Jehovah's Witness               <$10k     20\n",
      "9                     Jewish               <$10k     19\n",
      "10             Mainline Prot               <$10k    289\n",
      "11                    Mormon               <$10k     29\n",
      "12                    Muslim               <$10k      6\n",
      "13                  Orthodox               <$10k     13\n",
      "14           Other Christian               <$10k      9\n",
      "15              Other Faiths               <$10k     20\n",
      "16     Other World Religions               <$10k      5\n",
      "17              Unaffiliated               <$10k    217\n",
      "18                  Agnostic             $10-20k     34\n",
      "19                   Atheist             $10-20k     27\n",
      "20                  Buddhist             $10-20k     21\n",
      "21                  Catholic             $10-20k    617\n",
      "22        Don’t know/refused             $10-20k     14\n",
      "23          Evangelical Prot             $10-20k    869\n",
      "24                     Hindu             $10-20k      9\n",
      "25   Historically Black Prot             $10-20k    244\n",
      "26         Jehovah's Witness             $10-20k     27\n",
      "27                    Jewish             $10-20k     19\n",
      "28             Mainline Prot             $10-20k    495\n",
      "29                    Mormon             $10-20k     40\n",
      "..                       ...                 ...    ...\n",
      "150                    Hindu               >150k     54\n",
      "151  Historically Black Prot               >150k     78\n",
      "152        Jehovah's Witness               >150k      6\n",
      "153                   Jewish               >150k    151\n",
      "154            Mainline Prot               >150k    634\n",
      "155                   Mormon               >150k     42\n",
      "156                   Muslim               >150k      6\n",
      "157                 Orthodox               >150k     46\n",
      "158          Other Christian               >150k     12\n",
      "159             Other Faiths               >150k     41\n",
      "160    Other World Religions               >150k      4\n",
      "161             Unaffiliated               >150k    258\n",
      "162                 Agnostic  Don't know/refused     96\n",
      "163                  Atheist  Don't know/refused     76\n",
      "164                 Buddhist  Don't know/refused     54\n",
      "165                 Catholic  Don't know/refused   1489\n",
      "166       Don’t know/refused  Don't know/refused    116\n",
      "167         Evangelical Prot  Don't know/refused   1529\n",
      "168                    Hindu  Don't know/refused     37\n",
      "169  Historically Black Prot  Don't know/refused    339\n",
      "170        Jehovah's Witness  Don't know/refused     37\n",
      "171                   Jewish  Don't know/refused    162\n",
      "172            Mainline Prot  Don't know/refused   1328\n",
      "173                   Mormon  Don't know/refused     69\n",
      "174                   Muslim  Don't know/refused     22\n",
      "175                 Orthodox  Don't know/refused     73\n",
      "176          Other Christian  Don't know/refused     18\n",
      "177             Other Faiths  Don't know/refused     71\n",
      "178    Other World Religions  Don't know/refused      8\n",
      "179             Unaffiliated  Don't know/refused    597\n",
      "\n",
      "[180 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "pew_long = pd.melt(pew, id_vars='religion')\n",
    "print(pew_long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    religion              income  count\n",
      "0                   Agnostic               <$10k     27\n",
      "1                    Atheist               <$10k     12\n",
      "2                   Buddhist               <$10k     27\n",
      "3                   Catholic               <$10k    418\n",
      "4         Don’t know/refused               <$10k     15\n",
      "5           Evangelical Prot               <$10k    575\n",
      "6                      Hindu               <$10k      1\n",
      "7    Historically Black Prot               <$10k    228\n",
      "8          Jehovah's Witness               <$10k     20\n",
      "9                     Jewish               <$10k     19\n",
      "10             Mainline Prot               <$10k    289\n",
      "11                    Mormon               <$10k     29\n",
      "12                    Muslim               <$10k      6\n",
      "13                  Orthodox               <$10k     13\n",
      "14           Other Christian               <$10k      9\n",
      "15              Other Faiths               <$10k     20\n",
      "16     Other World Religions               <$10k      5\n",
      "17              Unaffiliated               <$10k    217\n",
      "18                  Agnostic             $10-20k     34\n",
      "19                   Atheist             $10-20k     27\n",
      "20                  Buddhist             $10-20k     21\n",
      "21                  Catholic             $10-20k    617\n",
      "22        Don’t know/refused             $10-20k     14\n",
      "23          Evangelical Prot             $10-20k    869\n",
      "24                     Hindu             $10-20k      9\n",
      "25   Historically Black Prot             $10-20k    244\n",
      "26         Jehovah's Witness             $10-20k     27\n",
      "27                    Jewish             $10-20k     19\n",
      "28             Mainline Prot             $10-20k    495\n",
      "29                    Mormon             $10-20k     40\n",
      "..                       ...                 ...    ...\n",
      "150                    Hindu               >150k     54\n",
      "151  Historically Black Prot               >150k     78\n",
      "152        Jehovah's Witness               >150k      6\n",
      "153                   Jewish               >150k    151\n",
      "154            Mainline Prot               >150k    634\n",
      "155                   Mormon               >150k     42\n",
      "156                   Muslim               >150k      6\n",
      "157                 Orthodox               >150k     46\n",
      "158          Other Christian               >150k     12\n",
      "159             Other Faiths               >150k     41\n",
      "160    Other World Religions               >150k      4\n",
      "161             Unaffiliated               >150k    258\n",
      "162                 Agnostic  Don't know/refused     96\n",
      "163                  Atheist  Don't know/refused     76\n",
      "164                 Buddhist  Don't know/refused     54\n",
      "165                 Catholic  Don't know/refused   1489\n",
      "166       Don’t know/refused  Don't know/refused    116\n",
      "167         Evangelical Prot  Don't know/refused   1529\n",
      "168                    Hindu  Don't know/refused     37\n",
      "169  Historically Black Prot  Don't know/refused    339\n",
      "170        Jehovah's Witness  Don't know/refused     37\n",
      "171                   Jewish  Don't know/refused    162\n",
      "172            Mainline Prot  Don't know/refused   1328\n",
      "173                   Mormon  Don't know/refused     69\n",
      "174                   Muslim  Don't know/refused     22\n",
      "175                 Orthodox  Don't know/refused     73\n",
      "176          Other Christian  Don't know/refused     18\n",
      "177             Other Faiths  Don't know/refused     71\n",
      "178    Other World Religions  Don't know/refused      8\n",
      "179             Unaffiliated  Don't know/refused    597\n",
      "\n",
      "[180 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "pew_long = pd.melt(pew, id_vars=\"religion\", var_name='income', value_name='count')\n",
    "print(pew_long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 2개 이상의 열을 고정하고 나머지 열을 행으로 바꾸기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "billboard = pd.read_csv('../data/billboard.csv')\n",
    "\n",
    "print(billboard.iloc[0:5, 0:16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "billboard_long = pd.melt(billboard, id_vars=['year','artist','track','time','date.entered'], var_name='week',value_name='rating')\n",
    "print(billboard_long.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 07-2. 열 이름 관리하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__split 메서드로 열 이름 분리__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## ebola 데이터 집합 살펴보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ebola = pd.read_csv('../data/country_timeseries.csv')\n",
    "print(ebola.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ebola.iloc[:5, [0,1,2,3,10,11]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 다음과 같은 결과가 나오도록 melt 메서드 적용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date  Day      variable   value\n",
      "0    1/5/2015  289  Cases_Guinea  2776.0\n",
      "1    1/4/2015  288  Cases_Guinea  2775.0\n",
      "2    1/3/2015  287  Cases_Guinea  2769.0\n",
      "3    1/2/2015  286  Cases_Guinea     NaN\n",
      "4  12/31/2014  284  Cases_Guinea  2730.0\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`split`__ Cases_Guinea와 같이 2개 이상의 의미를 가지고 있는 열 이름은 밑줄('_')을 기준으로 Cases, Guinea와 같은 방법으로 분리할 수 있다. split 메서드는 기본적으로 공백을 기준으로 문자열을 자른다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 열 이름 분리하고 데이터프레임에 추가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_split = ebola_long.variable.str.split('_')\n",
    "print(variable_split[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(variable_split)) #variable_split에 저장된 자료형은 시리즈\n",
    "print(type(variable_split[0])) #시리즈에 저장된 값(열 이름)의 자료형은 리스트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 리스트의 0번째 인덱스에 담긴 문자열은 발병(Cases)/죽음(Deaths)\n",
    "- 1번째 인덱스에 담긴 문자열은 나라 이름"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__get 메서드__ 를 사용하여 0,1번째 인덱스의 데이터 한꺼번에 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status_values = variable_split.str.get(0)\n",
    "country_values = variable_split.str.get(1)\n",
    "\n",
    "print(status_values[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(country_values[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 위에서 분리한 문자열을 status, country라는 열 이름으로 데이터 프레임에 추가하자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ebola_long['status']=status_values\n",
    "ebola_long['country']=country_values\n",
    "\n",
    "print(ebola_long.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## concat 메서드를 응용하여 데이터프레임에 열 추가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_split = ebola_long.variable.str.split('_',expand=True) #expand=T는 결과물을 데이터프레임으로 만든다.\n",
    "variable_split.columns = ['status','country']\n",
    "ebola_parsed = pd.concat([ebola_long, variable_split],axis=1) #axis=1 : 열 방향으로 합치기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ebola_parsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 07-3 여러 열을 하나로 정리하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## melt, pivot_table 메서드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = pd.read_csv('../data/weather.csv')\n",
    "print(weather.iloc[:5,:11])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 열의 날짜 데이터 행으로 위치 변경하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id  year  month element day  temp\n",
      "0  MX17004  2010      1    tmax  d1   NaN\n",
      "1  MX17004  2010      1    tmin  d1   NaN\n",
      "2  MX17004  2010      2    tmax  d1   NaN\n",
      "3  MX17004  2010      2    tmin  d1   NaN\n",
      "4  MX17004  2010      3    tmax  d1   NaN\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 행과 열의 위치 변경하기\n",
    "##### : element의 value를 열로, temp를 value열의 데이터로 가져오기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__pivot_table 메서드__ 데이터를 재구성해 자료의 집계나 평균과 같은 통계량을 정리한 피벗 테이블을 만든다. \n",
    "- __메서드 인자__\n",
    " - __index__ : 만들어지는 피벗테이블의 로우를 그룹으로 묶을 컬럼 이름이나 그룹 키\n",
    " - __values__ : 집계하려는 컬럼 이름 혹은 이름의 리스트.\n",
    " - __columns__ : 만들어지는 피벗테이블의 컬럼을 그룹으로 묶을 컬럼 이름이나 그룹 키\n",
    " - __aggfunc__ : 집계함수나 함수 리스트. 기본값은 'mean'\n",
    " - __fill_value__ : 결과테이블에서 누락된 값을 대체하기 위한 값\n",
    " - __dropna__ : True이면 모든 항목이 NA인 컬럼은 포함하지 않는다.\n",
    " - __margin__ : 부분합이나 총계를 담기 위한 로우/컬럼을 추가할지 여부"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_tidy = weather_melt.pivot_table(\n",
    "    index=['id','year','month','day'],\n",
    "    columns='element',\n",
    "    values='temp'\n",
    ")\n",
    "\n",
    "print(weather_tidy.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 부분합 구하기 : margins=True\n",
    "margins=True를 넘겨서 부분합을 포함시키면 All 컬럼과 All 로우가 추가되어 단일 줄 안에서 그룹 통계를 얻을 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_tidy = weather_melt.pivot_table(\n",
    "    index=['id','year','month','day'],\n",
    "    columns='element',\n",
    "    values='temp',\n",
    "    margins=True\n",
    ")\n",
    "\n",
    "print(weather_tidy.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### margin에서 집계 함수 변경 : aggfunc = 'count', len\n",
    "집계함수에서 'count'나 len 함수는 그룹 크기의 교차일람표(총 개수나 빈도)를 반환한다. 'mean'등의 통계량 사용 가능하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_tidy = weather_melt.pivot_table(\n",
    "    index=['id','year','month','day'],\n",
    "    columns='element',\n",
    "    values='temp',\n",
    "    margins=True,\n",
    "    aggfunc='count'\n",
    ")\n",
    "\n",
    "print(weather_tidy.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결측치가 있다면 fill_value로 처리할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_tidy = weather_melt.pivot_table(\n",
    "    index=['id','year','month','day'],\n",
    "    columns='element',\n",
    "    values='temp',\n",
    "    margins=True,\n",
    "    aggfunc='mean',\n",
    "    fill_value=0\n",
    ")\n",
    "\n",
    "print(weather_tidy.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reset_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_tidy.element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_tidy_flat = weather_tidy.reset_index()\n",
    "print(weather_tidy_flat.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 07-4. 중복 데이터 처리하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 빌보드 차트의 중복 데이터 처리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year        artist                    track  time date.entered week  rating\n",
      "0  2000         2 Pac  Baby Don't Cry (Keep...  4:22   2000-02-26  wk1    87.0\n",
      "1  2000       2Ge+her  The Hardest Part Of ...  3:15   2000-09-02  wk1    91.0\n",
      "2  2000  3 Doors Down               Kryptonite  3:53   2000-04-08  wk1    81.0\n",
      "3  2000  3 Doors Down                    Loser  4:24   2000-10-21  wk1    76.0\n",
      "4  2000      504 Boyz            Wobble Wobble  3:35   2000-04-15  wk1    57.0\n"
     ]
    }
   ],
   "source": [
    "billboard = pd.read_csv('../data/billboard.csv')\n",
    "billboard_long = pd.melt(billboard, id_vars=['year','artist','track','time','date.entered'], var_name='week', value_name='rating')\n",
    "print(billboard_long.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### track이 Loser인 것만 모아보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(billboard_long[billboard_long.track == 'Loser'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "중복 데이터가 많은 것을 볼 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 중복 데이터를 가진 열(year, artist, track, time) 새 데이터 프레임에 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "billboard_songs = billboard_long[['year','artist','track','time']]\n",
    "print(billboard_songs.shape)                                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 중복 데이터 제거 - drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "billboard_songs = billboard_songs.drop_duplicates()\n",
    "print(billboard_songs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 중복을 제거한 데이터에 id(행 순서)추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "billboard_songs['id']=range(len(billboard_songs))\n",
    "print(billboard_songs.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 노래 정보와 주간 순위 데이터 합치기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "billboard_ratings = billboard_long.merge(billboard_songs, on=['year','artist','track','time'])\n",
    "print(billboard_ratings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(billboard_ratings.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 07-5. 대용량 데이터 처리하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__여러 개로 나누어진 데이터 불러오기__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터를 나누어 저장하면 용량이 작아져 저장이나 공유에 유용하다. 또는 매일 수집하는 주식 정보처럼 여러 개의 작은 데이터가 생성되기도 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 뉴욕 택시 데이터 준비"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 내려받기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import urllib.request\n",
    "\n",
    "# 네트워크 상태에 따라 5 ~ 15분이 소요됩니다.\n",
    "with open('../data/raw_data_urls.txt', 'r') as data_urls:\n",
    "    for line, url in enumerate(data_urls):\n",
    "        if line == 5:\n",
    "            break \n",
    "        fn = url.split('/')[-1].strip()\n",
    "        fp = os.path.join('', '../data', fn)\n",
    "        print(url)\n",
    "        print(fp)\n",
    "        urllib.request.urlretrieve(url, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 저장된 5개의 파일 한꺼번에 불러오기\n",
    "내려받은 파일은 data폴더에 'fhv_tripdata_YYYY_MM.csv'로 저장된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "nyc_taxi_data = glob.glob('../data/fhv_*')\n",
    "print(nyc_taxi_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 각각의 파일을 데이터 프레임으로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi1 = pd.read_csv(nyc_taxi_data[0])\n",
    "taxi2 = pd.read_csv(nyc_taxi_data[1])\n",
    "taxi3 = pd.read_csv(nyc_taxi_data[2])\n",
    "taxi4 = pd.read_csv(nyc_taxi_data[3])\n",
    "taxi5 = pd.read_csv(nyc_taxi_data[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 잘 불러왔는지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(taxi1.head(2))\n",
    "print(taxi2.head(2))\n",
    "print(taxi3.head(2))\n",
    "print(taxi4.head(2))\n",
    "print(taxi5.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 각 데이터의 행과 열 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(taxi1.shape)\n",
    "print(taxi2.shape)\n",
    "print(taxi3.shape)\n",
    "print(taxi4.shape)\n",
    "print(taxi5.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터가 꽤 크다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### taxi1~5를 행 방향으로 연결"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi = pd.concat([taxi1,taxi2,taxi3,taxi4,taxi5]) #axis=0 : 행방향\n",
    "print(taxi.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 반복문으로 데이터 준비하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5개의 csv 파일을 데이터 프레임으로 변환하여 리스트에 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_taxi_df = []\n",
    "\n",
    "for csv_filename in nyc_taxi_data:\n",
    "    # print(csv_filename)\n",
    "    df = pd.read_csv(csv_filename)\n",
    "    list_taxi_df.append(df)\n",
    "    \n",
    "print(len(list_taxi_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(list_taxi_df[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list_taxi_df[0].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "list_taxi_df라는 리스트 안에 데이터 프레임이 저장되어있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 리스트에 있는 5개의 데이터 프레임 합치기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_loop_concat = pd.concat(list_taxi_df)\n",
    "print(taxi_loop_concat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(taxi.equals(taxi_loop_concat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞에서 만든 taxi 데이터 프레임과 반복문을 이용한 taxi_loop_concat 데이터 프레임이 동일하다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
